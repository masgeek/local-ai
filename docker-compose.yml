services:
  local-ai:
    image: localai/localai:latest-gpu-nvidia-cuda-13
    container_name: local-ai
    ports:
      - "8080:8080"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    stdin_open: true   # equivalent to -ti
    tty: true          # equivalent to -ti
